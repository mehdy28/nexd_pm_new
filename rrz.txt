the user logs in here is redirected in the workspace page .
- workspace page : has the name and description of the project . it has list of users u can invite users . it has list of projects u can create a project. once u click on the project it takes u to the project page .
- project page : composed of tabs.
   * overview tab : name of the project . some kpis . list of members u can add a memeber to the project from the list of workspace members. there is list of sprints and their discriptions and start and end dater u can create a sprint .
   * list tab : u have a drop down menu to filter the tasks based on the sprint list of all the sections below each section list of all tasks . a task contain name priority story point  assignerr and due date . once a task is clicked  a modal appears it has the description section the comments sections the attachements section and the activities section to capture what happened to that task. 
   * board view : the same as list view but it is kanban board .
   * gantt view : it has a gantt chart where u can manipulate tasks and see them monthly or weekly or yearly or quarterly . u can filter via sprint.
   * documents tab : it has list of documents when u click on one it opens a notion like editor in the left and a comments section in the right . u can create a blank document or use a built in template from the list of templates . u have a thumbnail of each template.
   * whiteboard view : u have list of whiteboards and u can create from template or blank . u can see the thumbnail of the whiteboards .a whiteboard is an excalidraw . u can create a pompt by opening a modal in the whiteboard editor and it takes a screenshot of the draw and then u can generate a prompt based on it from ai . and save the prompt . for example u draw an architecture of a system and then use the modal to create a prompt that the user can feed to an external ai tool.
   * prompt tab : list of prompts and also templates . a prompt once clicked a prompt lab opens where u can create many versions of it . the prompt content  is composed of drag and drop blocks  text block and variable block ( a variable can be a simple placeholder or the user can create inteligent variable from a ms power bi like system it is a modal for example u can select all the tasks for a certain sprint that arre marked as not done yet and hiigh priority) . the user can select the name of the modal and save the prompt to use it later in its ai agent . once the user created a prompt he can enhance it with ai to get an optimised prompt . it is a prompt management system built in in the project management saas.
   * a dashboard of kpis and charts.
   
   
   
- my tasks page : sismilar to the project page but for the user proper tasks that are not part of a project it has the list view tab . the board tab . the documents tab . the whiteboard tab . the prompt lab tab . a dashboard tab.

- a messaging page for the entire workspace . the user can create and chat in direct msgs or group msgs or create tickets for the support of the saas for any matter .

- account page : the user can update his name lastname . color of a vatar . reset his password.











GPT-5.2
OpenAI
Put clear instructions at the prompt's beginning using ### or """ delimiters to separate from context. Explicitly request step-by-step thinking when reasoning is needed (e.g., "Think step-by-step before responding"). Use tool descriptions with allowed_tools constraints and add tool preambles explaining usage for reliability. Control verbosity via parameters rather than prose; favor concise, task-focused outputs with strong instruction adherence.


GPT-5.1
OpenAI
Emphasize explicit reasoning chains: "Outline your plan first, then execute step-by-step." Leverage compaction for long tasks and request understandable intermediate responses. Design around tools over sequences, grounding outputs in provided data to minimize ambiguity.
       

Claude Opus 4.5
Anthropic	
Be highly explicit with instructions, providing motivation/context and aligning examples strictly to desired behaviors. Use modifiers for quality (e.g., "Think carefully"), suggest actions to take rather than avoid, and request JSON/XML for structured outputs. Excel at long-horizon reasoning; frame for parallel tool use and state tracking across turns.


Gemini 3	
Google	
Use direct, concise instructions with defined parameters and XML tags for structure. Treat multimodal inputs equally; explicitly request elaborate responses if not succinct by default. Maintain consistency to enable agentic tool use and reasoning chains.



Gemini 2.5 Flash	
Google
Prioritize low-latency prompts: state goals clearly without fluff. Explicitly define vague terms and manage length by requesting verbosity levels. Integrate vision/text seamlessly for whiteboard/prompt generation.


Grok 4.1	
xAI
Establish persona in system prompt (e.g., "You are a helpful project manager"), then provide task data. Encourage tool calls (web_search, code_execution) with explanations of why to use them. Add guardrails like "Be concise, number steps, ask clarifying questions." Focus on emotional intelligence and reduced hallucinations via clear, creative framing.


Nano Banana Pro	
Google
Leverage world knowledge for context-rich image edits; use natural language prompts for multi-image fusion, character preservation, and scene-aware processing. Specify "analyze whiteboard elements spatially, extract text/diagrams step-by-step, output structured prompt blocks" for precise visual-to-text conversion. Maintain composition and integrate real-time details without breaking visuals.


Gemini 3 Pro Vision	
Google
Provide images first, then explicit instructions for spatial reasoning, pointing (pixel coordinates), and open-vocabulary object detection. Request "Describe layout, relationships, and content hierarchically; generate JSON with extracted elements for prompt blocks." Handles documents, videos, screens with state-of-the-art accuracy.



GPT-5.2 Vision	
OpenAI	
Start with image + clear directives using ### delimiters: "Analyze spatial layout, identify components (text, shapes, flows), reason step-by-step on relationships." Request JSON outputs for charts/UI; emphasize visual details like positioning to halve errors in diagrams/whiteboards.



Llama 3.1 Vision	
Meta	
Use for local deployment: "Step-by-step visual reasoning on images, extract entities/relations for SaaS prompts." Balances accuracy/portability for private vision tasks.



